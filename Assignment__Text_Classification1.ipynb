{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment _Text Classification1 ",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/auth-csd-nlp-2018/Sidiras_Liapikos2/blob/master/Assignment__Text_Classification1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "d18dojbX7nZY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#  Part 1: Basic operations with word embeddings\n",
        "1.Train a Word2Vec model on the WikiText dataset (Use the wiki.train.tokens corpus in the WikiText-103 word level corpus, which can be found here: https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/). Find the 5 most similar word pairs from the 10 most frequent words using a Gensim’s function.\n",
        "2. Then, implement a function that retrieves two word vectors using the indexing operator as described in Gensim’s documentation and computes their cosine distance. You may be interested in np.dot() and np.linalg.norm() - see the numpy documentation for details. Compare this to the distance computed by Gensim's functions.\n",
        "3. Visit the NLPL word embedding repository (http://vectors.nlpl.eu/repository/) and download the models with the following identifiers:\n",
        "(40. It was trained on the English CoNLL17 corpus, using Continuous Skip-gram algorithm with vector size 100, and window size 10.\n",
        "(75. It was trained on the English Oil and Gas corpus, using Continuous Bag-of-Words algorithm with vector size 400, and window size 5.\n",
        "(82. It was trained on the English Common Crawl Corpus, using GloVe algorithm with vector size 300, and window size 10.\n",
        "4. Use your trained and above downloaded pre-trained embeddings to compare the lists of top 20 most frequent words in WikiText, CoNLL17, Oil and Gas, and Common Crawl corpora.\n",
        "In Gensim, one can access the model vocabulary sorted by frequency as MODEL.index2word list.\n",
        "If a model is saved in the native Gensim format, one can also access the words frequencies in the training corpus (as integers) with the MODEL.wv.vocab[’YOUR_WORD’].count method.\n",
        "Note also that if a model is saved as a text file in the word2vec format, its lines are as a rule sorted by frequency as well. Thus, top 20 lines of the file correspond to 20 most frequent words in the training corpus\n",
        "5. Are the lists different? What does it tell you about the nature of these corpora?\n",
        "6. Project top 1000 words from the WikiText corpus in 2d space using t-SNE plot. Find an interesting cluster in the plot."
      ]
    },
    {
      "metadata": {
        "id": "sviZOoAa7rM_",
        "colab_type": "code",
        "outputId": "ecf364d1-1a95-470d-f5b6-b4720af668b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fRF2Swtn7sYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s9bS0a45JUG3",
        "colab_type": "code",
        "outputId": "eb5e9098-5167-41b8-aab0-b5ecbec9ffa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hSei-1_9nJH5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This link is the original word2vec model\n",
        "https://arxiv.org/pdf/1301.3781.pdf"
      ]
    },
    {
      "metadata": {
        "id": "MF2zwomTCBor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "3d6b42c2-300e-4e29-e26c-1392fafceb5f"
      },
      "cell_type": "code",
      "source": [
        "# Install needed libraries\n",
        "!pip install bokeh\n",
        "!pip install lxml\n",
        "!pip install gensim"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.11.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh) (3.13)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.5.3)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh) (2.10)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from bokeh) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.0.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.6/dist-packages (from bokeh) (18.0)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh) (4.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.0->bokeh) (0.46)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=16.8->bokeh) (2.3.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.72)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.72 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.72)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.72->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GjNLroOLCIAc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUanxHQSCO4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import lxml.etree\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3c6fllb-nN7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import nltk\n",
        "import os\n",
        "from random import shuffle\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qZZPOQwrRDN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c1d4be4d-6d31-4017-b576-e80efb9fb802"
      },
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "from os import listdir\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CyRqnbFRjnvk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14f174b3-f668-4c39-f248-5192989a9a3d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dV4IvOgOnJII",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_filename = '/content/drive/My Drive/Colab Notebooks/wikitext-103/wiki.train.tokens'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmQNvJ_2pyYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3ER5oqoYr6wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "59b0d736-4f95-4131-bb52-94bc7434e29d"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2be0aba89dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/drive/'My Drive'/'wiki.train.tokens'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_doc' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YpBWNwSZHAat",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "00b76634-cb50-4795-e6ec-4f4932445af8"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f54AB3k2u2V7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97d5ec63-0ceb-4cba-bd65-9ffde3eb9414"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#!cwd = os.getcwd()  # Get the current working directory (cwd)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 0: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 0: `cwd = os.getcwd()  # Get the current working directory (cwd)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5sEeKhciu3Ic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctLAp4Je7cQM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8db63f29-911d-4727-f833-0f289a592cae"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: 'drive/My Drive/': Is a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RQm1QMCT938A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d993b573-897e-4d4c-b158-3cce8bc9f5c7"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'fg': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K5L97Nus97ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbccb8af-cc7b-44de-ca1e-bc4af4c6a5c3"
      },
      "cell_type": "code",
      "source": [
        "!ls vocab_filename"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'vocab_filename': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NyQxVPfTNukf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_filename = '/content/drive/My Drive/wiki.train.tokens'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIBvnABgBbvI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "file = open(vocab_filename,'r', encoding=\"utf8\") \n",
        "\t# read all text\n",
        "text = file.read()\n",
        "\t# close the file\n",
        "file.close()\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "doBDLXPAKwK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9eb3c606-11c0-4a44-9b53-44ff6843934c"
      },
      "cell_type": "code",
      "source": [
        "sentences[1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "kFJejxC6K0CW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "acef5254-cd10-476e-d6bb-341c0d6cb56f"
      },
      "cell_type": "code",
      "source": [
        "text=re.sub(r'\\[[0-9]*\\]', ' ',text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-0943cf625cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\[[0-9]*\\]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "E8wOrVdMTpVs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text=re.sub(r'\\s+',' ',text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STy0NkLEUjTg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text=text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ata6gafgUzI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "417ed63b-079f-4766-fbb6-4a378612e13e"
      },
      "cell_type": "code",
      "source": [
        "text=re.sub(r'[@#\\$%&\\*\\(\\)\\<\\>\\?\\'\\'\\]'\\\":;]')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-380773f90612>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    text=re.sub(r'[@#\\$%&\\*\\(\\)\\<\\>\\?\\'\\'\\]'\\\":;]')\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Rb__jxbqVDJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text=re.sub(r'\\d',' ',text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KO0TJbkdVLNZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text=re.sub(r'\\s+',' ',text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wGSo_8kLWuua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "63c64410-d6f0-48bd-a82a-287b1bfaa67c"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "iPKzoRWVVcUf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTTWW3GgrOqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmqCU_k737Ue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_ted = []\n",
        "for sent_str in sentences:\n",
        "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent_str.lower()).split()\n",
        "    sentences_ted.append(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BoBlExbpUmC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51e6fa1c-52f8-42db-d027-22985658bb65"
      },
      "cell_type": "code",
      "source": [
        "print(len(sentences_ted))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3857367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Lqt0nuBieFS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #Training the Word2Vec model\n",
        "model = Word2Vec(sentences_ted, min_count=1)\n",
        "\n",
        "words = model.wv.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_sb6wlxU5lA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2d1192c0-0210-49f8-bba0-c1251270c43e"
      },
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3rXT_F0oVyOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b37bf80-ebd3-4072-f5dd-a21bd04eb9af"
      },
      "cell_type": "code",
      "source": [
        "print((len(words)))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "212925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pa7icJRNXqyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "47b2e368-6419-4470-c647-dbc8d92df0f4"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-288dbdf7cdaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Yu3bioBkXBcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ybmHBxWmXSYh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Word2Vec(sentences, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LknpjWPXV33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = model.wv.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBl4fkOc905e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vector=model.wv['global']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPDZYCiY956O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#remove stop words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m7DTHVno98vW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7782bb3a-c7e6-40bd-99e4-de2d134888bb"
      },
      "cell_type": "code",
      "source": [
        "similar = model.wv.most_similar('global')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "60hp9YiyBHao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "a8c59af3-858e-40ba-ef94-731490d54349"
      },
      "cell_type": "code",
      "source": [
        "similar\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('earl', 0.44806504249572754),\n",
              " ('redshanks', 0.41169124841690063),\n",
              " ('sawfish', 0.4112607538700104),\n",
              " ('throats', 0.40485912561416626),\n",
              " ('upmanship', 0.3979750871658325),\n",
              " ('orley', 0.397551953792572),\n",
              " ('polecat', 0.3934825360774994),\n",
              " ('guzla', 0.3916468024253845),\n",
              " ('fluffed', 0.3910376727581024),\n",
              " ('depreciates', 0.3894854784011841)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "metadata": {
        "id": "hLWYOuY1BQiF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "e8603650-4076-477b-8b00-da67d03f7169"
      },
      "cell_type": "code",
      "source": [
        "!pip install space"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting space\n",
            "  Downloading https://files.pythonhosted.org/packages/49/33/68fbb59b5edc5331945cca0651adf3f06f1884acacefbda11354af5a31c1/space-0.1.5.tar.gz\n",
            "Collecting spacepy<0.2.0,>=0.1.5 (from space)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/10/4a9a43014d25c1ce08aad136da2515eb120a26105dec5e8f42b5986c22a3/spacepy-0.1.6.tar.gz (11.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 11.1MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.4 in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.7 in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=0.99 in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (2.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (2.8.0)\n",
            "Collecting ffnet (from spacepy<0.2.0,>=0.1.5->space)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/19/88aa36c3c8e3253db9846ab29b7ec731437736fdd99affb404e2c0cd15a1/ffnet-0.8.4.tar.gz (55kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (2.2)\n",
            "Requirement already satisfied: python_dateutil in /usr/local/lib/python3.6/dist-packages (from spacepy<0.2.0,>=0.1.5->space) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=0.99->spacepy<0.2.0,>=0.1.5->space) (0.10.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib>=0.99->spacepy<0.2.0,>=0.1.5->space) (2018.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=0.99->spacepy<0.2.0,>=0.1.5->space) (1.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=0.99->spacepy<0.2.0,>=0.1.5->space) (2.3.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->spacepy<0.2.0,>=0.1.5->space) (4.3.0)\n",
            "Building wheels for collected packages: space, spacepy, ffnet\n",
            "  Running setup.py bdist_wheel for space ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/36/f3/ab/37060975bba53220537b32499d3c993906261e616a465cf491\n",
            "  Running setup.py bdist_wheel for spacepy ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/17/32/65/79047adb4b411ad0c87ffdca8e8d5c8285aa12cf95fd6f373f\n",
            "  Running setup.py bdist_wheel for ffnet ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/46/b6/2d/9e361c6b5fccc94caac287ccdd308bd291de9cece07e19d10d\n",
            "Successfully built space spacepy ffnet\n",
            "Installing collected packages: ffnet, spacepy, space\n",
            "Successfully installed ffnet-0.8.4 space-0.1.5 spacepy-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CiLt593hO8Di",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "85126cc6-1387-4419-d73d-7de83a36cec6"
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download 'en'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bURV521CQZUT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7UhC9uI9PkFo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#nlp=spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9k4rFCRQXCx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#vocab_filename = '/content/drive/My Drive/wiki.train.tokens'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35j196CqSTqz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#file = open(vocab_filename,'r', encoding=\"utf8\") \n",
        "\t# read all text\n",
        "#text = file.read()\n",
        "\t# close the file\n",
        "#file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NpIUKIsISVm-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "01a3c223-1884-4796-db41-7fedd3bcb704"
      },
      "cell_type": "code",
      "source": [
        "#doc=nlp(text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-39da4096c184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             raise ValueError(Errors.E088.format(length=len(text),\n\u001b[0;32m--> 339\u001b[0;31m                                                 max_length=self.max_length))\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E088] Text of length 538360726 exceeds maximum of 1000000. The v2.x parser and NER models require roughly 1GB of temporary memory per 100,000 characters in the input. This means long texts may cause memory allocation errors. If you're not using the parser or NER, it's probably safe to increase the `nlp.max_length` limit. The limit is in number of characters, so you can check whether your inputs are too long by checking `len(text)`."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SqKHzWPvS60c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xqvyrkXNTJWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}